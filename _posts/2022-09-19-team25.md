---
layout: post
comments: true
title: Canonical Example of Heterogeneous Multi-agent Reinforcement Learning
author: Nour Yehia, Joshua Duquette, Valen Xie (Team 25)
date: 2022-10-18
---

> The problem we are addressing is the canonical example of HMARL: having two (or more) agents tasked with reaching a target in a gridworld-like environment. One agent is fast and able to observe the environment in an egocentric way and the other is slow and only observes what is directly in front of it. The faster agent cannot move obstacles, while the slower one can. The intent is to teach them to work together in order to clear the obstacles and reach some target in a specified amount of steps. (You should describe what is HMARL first!)


<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Potential Approach

One potential approach is to obtain agent observations from the environment and use those as input to a Resnet CNN or an RNN. Observations from both agents can be used as input, or we can use observations from only one of the agents and pass the ones from the other as a message later on. The NN used allows us to extract features from these observations, which can be passed to an LSTM to aggregate information from previous steps. We can then pass the LSTM output to an MLP action predictor to determine which action the agents should take next.

## Potential Environments

We found two potential environments that would be fitting for this project.

The first one comes from the first paper listed below in the form of a cellular automaton (CA). We can use a CA as a grid of agents, each with their own internal states and a rule that applies to all agents synchronously. This rule is usually based on the agents' current states. A CA is a good option because it has several hallmarks of a multi-agent system such as local interactions/communications and independently-performed behaviors.

The second potential environment comes from the second paper listed below. VirtualHome is a Unity-based environment and is designed for multi-agent collaborative tasks, which is the problem we want to tackle. It contains multiple scenes, each with multiple rooms and allows the initialization of objects at different locations.


## Relevant Papers

1. Liviu Panait, Sean Luke. “Cooperative Multi-Agent Learning: The State of the Art.” Autonomous Agents and Multi-Agent Systems, vol. 11, no. 3, 2005, pp. 387–434., https://doi.org/10.1007/s10458-005-2631-2. 

2. Goyal, Sharma, et al. “CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous Multi-Agent Reinforcement Learning.” Robotics Science and Systems Workshop, 2022, https://doi.org/https://doi.org/10.48550/arXiv.2208.13626.
