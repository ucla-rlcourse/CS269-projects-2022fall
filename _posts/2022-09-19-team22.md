---
layout: post
comments: true
title: Self-Play for Competitive Multi-Agent Gameplay
author: Ben Klingher, Erik Ren (Team 22)
date: 2022-10-19
---

> Self-play is a form of multi-agent reinforcement learning used for competitive game environments, where the agent is trained by competing against different versions of itself in order to improve performance. We intend to build a reinforcement learning system capable of training agents that compete successfully in multiple two-player competitive environments.
> 


## Summary
Self-play is a form of multi-agent reinforcement learning used for competitive game environments, where the agent is trained by competing against different versions of itself in order to improve performance. We intend to build a reinforcement learning system capable of training agents that compete successfully in multiple two-player competitive environments.

## Environment

We will train a competitve agent in two environments: Pong and Car Racing, using the environments impemented in [this repo](https://github.com/ucla-rlcourse/competitive-rl).

## Technique

As part of development, we plan to try out several approaches. We will expereiment with a policy gradient-based algorithm for training. We will also experiment with a Q-learning based model or a deep Q-learning model, perhaps both. When we have developed several successful agents, we will experiment with direct competition between agents based on the  independent algorithms. As time permits, we may deploy the self-play system to AWS Elastic Compute to accelerate the training. 

## Evaluation

To measure the performance of our trained agent, we plan to compare the win-rate of our model to a set of control agents. For example, the pong environment we use features 6 pre-trained agents ranked from random, rule-base, weak, medium, strong, and alpha. We will evaluate the win-rate for each of the control agents against our trained agent to determine both progress and success. We apply a similar evaluation method to all games played with the goal of reaching a positive win-rate.

For car racing, the envirnoment includes a scoring system, so a single agent's performance can be based on its success in this score. We will evaluate the agent based on iterative improvement. We will also deploy our agent against a baseline control agent that we will develop in the early stages of implementation.

## References

Emergent Complexity via Multi-Agent Competition
https://arxiv.org/pdf/1710.03748.pdf

Human-level control through deep reinforcement learning
https://www.nature.com/articles/nature14236

Deep Reinforcement Learning with Double Q-learning
https://arxiv.org/abs/1509.06461

Competitive Multi-Agent Reinforcement Learning with Self-Supervised Representation
https://ieeexplore.ieee.org/document/9747378