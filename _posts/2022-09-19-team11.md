---
layout: post
comments: true
title: Combining Imitation Learning with Reinforcement learning for autonomous driving in CARLA
author: Siqi Liu, Yiming Shi (Team 11)
date: 2022-10-12
---


> Imitation learning is wildly used in the Reinforcement learning field and allows the agent to mimic the action of a human. Imitation learning is also used in autonomous driving. However, simple imitation learning via behavior cloning is not sufficient as driving scenarios are sometimes very complex. In this project, we will explore the combination of imitation learning and other reinforcement learning methods to handle complex scenarios. 
<!-- (prev proposal)> Ususally driving involves multiple intelligent agents, intelligent machine or human. With more information cooperated, agents may performs differently to achieve their goals. In this projects, we want to research about Reinforcement Learning (RL) based method such that all the agents collaborate with each other to achieve the best goal in total. -->
<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction 
Recently, Reinforcement learning has been wildly used in autonomous driving. Since the driving task has high complexity and hard to construct a safe model or policy, imitation learning by behavior cloning becomes popular as it allows the agent to be trained to learn from a human expert and thus quickly learn to plan the action based on the complex environment and take actions. However, imitation learning is also suffered from issues such as failing unseen complex scenarios. In this project, we are aiming on reproducing a safe driving model based on imitation learning, analyzing failing cases for imitation learning and exploring ways such as adding loss besides imitation loss to discourage certain undesired behavior.

<!-- As 5G techniques become more mature, vehicle-to-everything (V2X) becomes possible. This allows vehicles to communicate with any entity that may affect, or may be affected by, the vehicle. A vehicle may use this information to act differently to achieve the final goal.  -->

## Proposed Work
Our project should be mainly two parts. In the first part, we will reproduce the result using imitation learning. In the second phase, we will try to add a policy or policy-based learning to encourage the desired behavior and punish the undesired behavior. We will test these under restrictions such as stop signs, speed limitations, and so on.

## Expected Result
We will first try to reproduce the result with imitation learning, we are expecting the agent are able to dring under simple environment without crashing. We alse expect that the result with imitation learning plus other reinforcement learning, we will reach much better result on complex senarios. 
Concretely, we will allow our agent to learn from the human driving example, then use reinforcement learning to broaden the model's training to create a safer model. 

We will first reproduce the imitation learning in CheuffeurNet. Then, we will use a reinforcement technique similar to Deep q-learning from demonstrations. 
In the process, we may face obstacles in combining the model's approaches and training curves, and a solution may be to perform our training by stages, by first using CheuffeurNet's training, then DqFD's. 
Therefore, we expect to deliver a method of training autonomous driving with a combination of imitation learning and reinforcement learning to the readers. 

## Related Work

Our Imitation learning work will follow CheuffeurNet[1]. 
Multiple similar works also use Imitation learning[2, 4].
Then, we perform the combination of Imitation learning and reinforcement learning following Deep d-learning from the demonstration[5].

### Platform
The platform we are going to work on is CARLA[6]. It is an open-source driving simulator that is able to construct simple and complex scenarios.

## References
1. Mayank Bansal, Alex Krizhevsky, & Abhĳit S. Ogale (2018). ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst. CoRR, abs/1812.03079.
2. Haan, P.D., Jayaraman, D., & Levine, S. (2019). Causal Confusion in Imitation Learning. NeurIPS.
3. Alexey Dosovitskiy, Germán Ros, Felipe Codevilla, Antonio M. Lόpez, & Vladlen Koltun (2017). CARLA: An Open Urban Driving Simulator. CoRR, abs/1711.03938.
4. Jinyun Zhou, Rui Wang, Xu Liu, Yifei Jiang, Shu Jiang, Jiaming Tao, Jinghao Miao, & Shiyu Song (2021). Exploring Imitation Learning for Autonomous Driving with Feedback Synthesizer and Differentiable Rasterization. CoRR, abs/2103.01882.
5. Hester, Todd, et al. "Deep q-learning from demonstrations." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 32. No. 1. 2018.
