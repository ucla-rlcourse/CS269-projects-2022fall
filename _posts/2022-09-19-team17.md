---
layout: post
comments: true
title: Reinforcement Learning for Autonomous Driving in a Realistic Simulated Urban Environment
author: Thomas Scott and Connor Couture (Team 17)
date: 2022-10-18
---


> Investigating the performance of various reinforcement learning strategies for self driving vehicles.

<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction
Hello everyone. We plan on exploring the use of reinforcement learning for self driving cars in realistic simulated urban environments. We plan on utilizing the autonomous vehicle research platform “CARLA”. CARLA allows researchers to study various autonomous vehicle systems in a highly realistic and customizable computer simulated environment. There are simulated sensors for self-driving vehicles in CARLA that are essentially one-to-one analogues to their real-world counterparts. Furthermore, the behavior of the surrounding simulated environment is highly modifiable, thus allowing us to test our agent in various environments. 

## Plan
This is our initial plan: We plan to train a single self-driving car using various reinforcement learning algorithms to navigate an urban environment through a set route. Initially having our environment and route fixed will allow us to measure the performance of various reinforcement learning algorithms against each other and potentially try strategies not seen in academic papers currently. Once we train our algorithm on a fixed environment, we plan to test its ability to generalize by setting up different (perhaps adversarial) scenarios for the algorithm to navigate. We plan on using only the realistic simulated sensors for our autonomous vehicles as well as a map of the environment. In conclusion, we expect to find the best performing reinforcement learning algorithm for an autonomous car in our realistic simulated environment.



## References
### CARLA Environment
[Dosovitskiy, et al.] "CARLA: An Open Urban Driving Simulator" [https://arxiv.org/pdf/1711.03938.pdf](https://arxiv.org/pdf/1711.03938.pdf)

### Associated Papers which may be Helpful
[Pérez-Gil, et al.] "Deep reinforcement learning based control for Autonomous Vehicles in CARLA" [https://link.springer.com/content/pdf/10.1007/](https://link.springer.com/content/pdf/10.1007/s11042-021-11437-3.pdf)  

[Liang, et al.] "Deep reinforcement learning based control for Autonomous Vehicles in CARLA" [https://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaodan_Liang_CIRL_Controllable_Imitative_ECCV_2018_paper.pdf](https://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaodan_Liang_CIRL_Controllable_Imitative_ECCV_2018_paper.pdf)

[Kendall, et al.] "Learning to Drive in a Day" [https://arxiv.org/pdf/1807.00412.pdf](https://arxiv.org/pdf/1807.00412.pdf)

[Emuna, et al.] "Deep Reinforcement Learning for Human-Like Driving Policies in Collision Avoidance Tasks of Self-Driving Cars" [https://arxiv.org/pdf/2006.04218.pdf](https://arxiv.org/pdf/2006.04218.pdf)

[Duan, et al.] "Hierarchical reinforcement learning for self driving decision-making without reliance on labeled driving data" [https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-its.2019.0317](https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/iet-its.2019.0317)

[Kiran, et al.] "Deep Reinforcement Learning for Autonomous Driving: A Survey" [https://arxiv.org/pdf/2002.00444.pdf](https://arxiv.org/pdf/2002.00444.pdf)

## November 11 Project Progress Update
### CARLA Environment Setup
To install the CARLA environment, we followed the steps on [https://carla.readthedocs.io/](https://carla.readthedocs.io/). On Windows, installation involved downloading the CARLA 0.9.12 zip file from [https://github.com/carla-simulator/carla/releases/tag/0.9.12/](https://github.com/carla-simulator/carla/releases/tag/0.9.12/). After extracting the zip, we ran CarlaUE4.exe which allowed us to explore a small environment.

![BEVCARLAEnvironment]({{ '/assets/images/team17/team17pageimg1.png' | relative_url }})

This birds-eye view shows the entire driveably area. When running CARLA, we are able to control the camera using W, A, S, D and the mouse.

Additionally, we are able to run python scripts to generate vehicle and pedestrian traffic. The vehicles in this new state drive around following set paths and obey traffic laws such as stopping at lights and yielding.

We are also able to manually control a vehicle in the environment by running another python script:

![CARLAVehicleControl]({{ '/assets/images/team17/team17pageimg2.png' | relative_url }})

There are also other scripts available, such as one that controls dynamic weather, which could pose challenges if we decided to go with a vision-based approach, rather than lidar. 

There is plenty of data provided on every vehicle, including collision, velocity, lane switch flags, simulated lidar, and more that we can use as input when training a model.

### Next Steps
We plan on setting up a basic urban environment which has other simulated vehicles, and we will set up a route in this environment for our agent. We will train agents on various algorithms on this route and then test their performance on other routes in our environment. Though we will start with a simpler platform, later on we may try having an agent that uses realistic simulated LIDAR input to train on.

These are the algorithms we plan on building and experimenting with initially:
- Deep Q Learning
- REINFORCE (Monte-Carlo Policy Gradient Method)
- Proximal Policy Optimization (with and without clipping)

If time and interest permits, we may also try out some model-based RL methods.

