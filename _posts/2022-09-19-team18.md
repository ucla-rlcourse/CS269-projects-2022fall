---
layout: post
comments: true
title: Autonomous driving based on CARLA
author: Zhi Zuo, Yinglu Deng (Team 18)
date: 2022-09-19
---

> These years, the tech giant companies have set off a boom in the development of autonomous driving, Waymo began as the Google self-driving car project in 2009, and the Tesla Motors announced its first version of Autopilot in 2014. So our team would also like to explore the autonomous driving skills by reinforcement learning.

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---
## Project Proposal
For this project, we will train a reinforcement learning model and deliver an autonomous car simulate the real urban environment by using [CARLA](https://carla.org/). The goal is to develop a car that can distinguish the complex urban layouts, avoid the barriers on the street and have different actions towards corresponding situations such as making a turn, slowing down and braking. 

Through viewing the CARLA paper [Autonomous Vehicle Control in CARLA Challenge](https://ebuah.uah.es/dspace/bitstream/handle/10017/45428/Autonomous_Egido_FIT_2020.pdf?isAllowed=y&sequence=1), we got interested working in the CARLA simulation for our autonomous driving cars. It is a perfect simulation for training the reinforcement learning to reach our goal. Tons of teams test their projects' performance through the platform of CARLA. For example, a team implements the DDPG car - [DDPG car-following model with real-world human driving experience in CARLA](https://arxiv.org/pdf/2112.14602v1.pdf). CARLA has been developed from the ground up to support development, training, and validation of autonomous driving system. 

<figure align="center">
  <img width="90%" src="../../../assets//images/team18/CARLA_simulation.png">
  <figcaption>Fig 1. CARLA simulation environment.</figcaption>
</figure>

## Driving Simulator Environments
### CARLA Basic Architecture:
**CARLA is mainly divided into two modules including Server and Client.** The Server is used to build the simulation world, and the Client is controlled by the user to adjust and change the simulation world.
- **Server**: The server side is responsible for everything related to the simulation itself: from 3D rendering cars, streets, buildings, building sensor models, to physics calculations, and more. It is like a creator, constructing the whole world, and updating the world according to the client's foreign instructions. It itself is based on 3D rendering made by UnrealEnigne.
- **Client**: If the server constructs the entire world, the client controls the world operates at different times. The user sends instructions to the server to guide the changes in the world by writing Python scripts (the latest version of C++ is also available), and the server executes according to the user's instructions.  In addition, the client side can also receive information from the server side, such as a road image captured by a camera.

### CARLA Key Features:
- **Traffic Manager**: CARLA creates the Traffic Manager to simulate a traffic environment similar to the real world. Users can define different models, behavior models, and speeds of vehicles to interact with the Ego-Vehicle. 
- **Sensors**: CARLA contains all kinds of sensor model simulating the real world, including cameras, Lidar, IMU, GNSS, and so on. The photos even have distortion and motion blur effects in order to mimic the effects in the real world. User can attach these sensors to different cars to collect various data. 

<figure align="center">
  <img width="90%" src="../../../assets//images/team18/environment.png">
  <figcaption>Fig 2. CARLA provided sensors information provided on each challenge track.</figcaption>
</figure>

- **Recorder**: The recorder module is used to record the status of each step for the purpose of reviewing, reproducing. 
- **ROS bridge**: CARLA can interact with ROS and Autoware. This module is important for testing the autopilot system in simulation. 
- **Open Assest**: Developer can add a customized object library to the simulation world with this module. For example, we can add a cool flying car to the default vehicle blueprint and the Client module can use it. 


## Progress


<figure align="center">
  <img width="90%" src="../../../assets//images/team18/DDPG.png">
  <figcaption>Fig 3. The conceptual framework of the two-stage DDPG agent. Stage 1: the agent updates networks with the simulation replay buffer. Stage 2: the agent learns from the modified practical replay buffer based on real driving datasets. </figcaption>
</figure>




## Toolkits and Libraries
[1] [CARLA Simulator Libraries](https://carla.readthedocs.io/en/latest/start_quickstart/#before-you-begin)

[2]Demo Video for [CARLA Simulator 0.9.13](https://carla.org/):
<p align="center">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/S2VIP0qumas" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>


## Project Timeline
- Week 3,4 - Confirmed the research topic, did research and read related paper.
- Week 5 - Brainstormed ideas, made a plan on the target model.
- Week 6 - Be familiar with the simulation environment.
- Week 7 - Tried writing agent with deep Q-learning.
- Week 8,9 - Built reinforcement learning model, did testing with different hyperparameters.
- Week 10,11 - Reviewed coding, updated and refined the report, did presentation.


## Team 18 Contact Info 
Zuo Zhi 
- UID: 305346349
- EMAIL: joannazz@g.ucla.edu

Yinglu Deng 
- UID: 305496193
- EMAIL: ceciliadeng12@g.ucla.edu


## Reference
[1] Akhloufi, M.A., Arola, S., Bonnet, A., 2019. Drones chasing drones: Reinforcement learning and deep search area proposal. Drones 3, 58.

[2] Bojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Monfort, M., Muller, U., Zhang, J., et al., 2016. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316 .
 
[3] Dworak, D., Ciepiela, F., Derbisz, J., Izzat, I., Komorkiewicz, M., Wojcik, M., 2019. Performance of lidar object detection deep learning architectures based on artificially generated point cloud data from carla simulator, in: 2019 24th International Conference on Methods and Models in Automation and Robotics(MMAR), IEEE. pp. 600–605.

[4] Gomez-Hu elamo, C., Del Egido, J., Bergasa, L.M., Barea, R., L opez-Guill en, E., Arango, F., Araluce, J., Lopez, J., 2020. Train here, drive there: Simulating real-world use cases with fully-autonomous driving architecture in carla simulator, in: Workshop of Physical Agents, Springer. pp. 44–59.

[5] He, Y., Zhao, N., Yin, H., 2017. Integrated networking, caching, and computing for connected vehicles: A deep reinforcement learning approach. IEEE Transactions on Vehicular Technology 67, 44–55.

[6] Isele, D., Rahimi, R., Cosgun, A., Subramanian, K., Fujimura, K., 2018. Navigating occluded intersections with autonomous vehicles using deep reinforcement learning, in: 2018 IEEE International Conference on Robotics and Automation (ICRA), IEEE. pp. 2034–2039.

[7] Liu, H., Huang, Z., Lv, C., 2021. Improved deep reinforcement learning with expert demonstrations for urban autonomous driving. arXiv preprint arXiv:2102.09243.

[8] MAURER. (2016). Autonomous Driving. Technical, Legal and Social Aspects. 10.1007/978-3-662-48847-8.

[9] Niranjan, D., VinayKarthik, B., et al., 2021. Deep learning based object detection model for autonomous driving research using carla simulator, in: 2021 2nd International Conference on Smart Electronics and Communication (ICOSEC), IEEE. pp. 1251–1258.

[10] ROHMER, E. (2013) "V-REP: A versatile and scalable robot simulation framework," 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, Tokyo, 2013, pp. 1321-1326. 

[11] Treiber, M., Kesting, A., 2017. The intelligent driver model with stochasticitynew insights into traffic flow oscillations. Transportation research procedia 23, 174–187.



---

*If you notice mistakes and errors in this post, don't hesitate to contact me at [lilian dot wengweng at gmail dot com] and I would be super happy to correct them right away!*
